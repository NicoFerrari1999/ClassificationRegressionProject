ggplot(Train_Possum, aes(earconch, sex)) + geom_point(shape = 16, color = "red") + geom_smooth(method = "lm", se = FALSE) +
ggtitle("Ear size & Sex") +
xlab("Ear size") +
ylab("Sex")
ggplot(Train_Possum, aes(eye, sex)) + geom_point(shape = 16, color = "red") + geom_smooth(method = "lm", se = FALSE) +
ggtitle("Eye size & Sex") +
xlab("Eye size") +
ylab("Sex")
ggplot(Train_Possum, aes(chest, sex)) + geom_point(shape = 16, color = "red") + geom_smooth(method = "lm", se = FALSE) +
ggtitle("Chest size & Sex") +
xlab("Chest size") +
ylab("Sex")
ggplot(Train_Possum, aes(belly, sex)) + geom_point(shape = 16, color = "red") + geom_smooth(method = "lm", se = FALSE) +
ggtitle("Belly size & Sex") +
xlab("Belly size") +
ylab("Sex")
mean_mae <- mean(mae_values)
mean_rmse <- mean(rmse_values)
mean_rsq <- mean(rsq_values)
# ---------- QUANTILE REGRESSION WITHOUT OUTLIERS ----------
model_cook <- lm(sex ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly, data = Possum_Dataset)
cooks_distance <- cooks.distance(model_cook)
threshold <- 4 * mean(cooks_distance, na.rm = TRUE)
outliers <- which(cooks_distance > threshold)
Possum_Dataset_Clear <- Possum_Dataset[-outliers, ]
set.seed(123)
index2 <- createDataPartition(Possum_Dataset_Clear$sex, p = 0.7, list = FALSE)
Train_Possum_Clear <- Possum_Dataset_Clear[index2, ]
Test_Possum_Clear <- Possum_Dataset_Clear[-index2, ]
mae_values_clear <- numeric(n_iter)
rmse_values_clear <- numeric(n_iter)
rsq_values_clear <- numeric(n_iter)
for (i in 1:n_iter) {
model_clear <- rq(sex ~ hdlngth + skullw + totlngth + taill + footlgth + earconch + eye + chest + belly, data = Train_Possum_Clear, tau = 0.5)
pred_clear <- predict(model_clear, newdata = Test_Possum_Clear)
mae_values_clear[i] <- mean(abs(pred_clear - Test_Possum_Clear$sex))
rmse_values_clear[i] <- sqrt(mean((pred_clear - Test_Possum_Clear$sex)^2))
rsq_values_clear[i] <- cor(pred_clear, Test_Possum_Clear$sex)^2
}
ggplot(Train_Possum_Clear, aes(hdlngth, sex)) + geom_point(shape = 16, color = "red") + geom_smooth(method = "lm", se = FALSE) +
ggtitle("Head length & Sex Cleaned") +
xlab("Head length Cleaned") +
ylab("Sex Cleaned")
ggplot(Train_Possum_Clear, aes(skullw, sex)) + geom_point(shape = 16, color = "red") + geom_smooth(method = "lm", se = FALSE) +
ggtitle("Skull width & Sex Cleaned") +
xlab("Skull width Cleaned") +
ylab("Sex Cleaned")
ggplot(Train_Possum_Clear, aes(totlngth, sex)) + geom_point(shape = 16, color = "red") + geom_smooth(method = "lm", se = FALSE) +
ggtitle("Possum total length & Sex Cleaned") +
xlab("Possum total length Cleaned") +
ylab("Sex Cleaned")
ggplot(Train_Possum_Clear, aes(taill, sex)) + geom_point(shape = 16, color = "red") + geom_smooth(method = "lm", se = FALSE) +
ggtitle("Tail length & Sex Cleaned") +
xlab("Tail length Cleaned") +
ylab("Sex Cleaned")
ggplot(Train_Possum_Clear, aes(footlgth, sex)) + geom_point(shape = 16, color = "red") + geom_smooth(method = "lm", se = FALSE) +
ggtitle("Foot length & Sex Cleaned") +
xlab("Foot length Cleaned") +
ylab("Sex Cleaned")
library(caTools)
library(class)
library(e1071)
library(caret)
library(Amelia)
HD_Dataset <- read.csv("C:\\Users\\Nico\\Desktop\\Progetto Morasca\\Classification\\heart.csv")
# Then we normalized the dataset so that the output remains unbiased.
normalize <- function(x){return ((x-min(x))/(max(x)-min(x)))}
HD_Dataset_Normalized <- as.data.frame(lapply(HD_Dataset, normalize))
n_iter <- 50
# We split the dataset into training set and testing set.
set.seed(123)
index <- sample(1:nrow(HD_Dataset_Normalized), 0.7 * nrow(HD_Dataset_Normalized))
Train_HD <- HD_Dataset_Normalized[index, 1:13]
Train_Label_HD <- HD_Dataset_Normalized[index, 14]
Test_HD <- HD_Dataset_Normalized[-index, 1:13]
Test_Label_HD <- HD_Dataset_Normalized[-index, 14]
accuracy <- c()
Train_Scale_HD <- scale(Train_HD)
Test_Scale_HD <- scale(Test_HD)
for (i in 1:n_iter) {
model <- knn(Train_HD, Test_HD, Train_Label_HD, k = i)
pred <- model
accuracy[i] <- mean(pred == Test_Label_HD)
}
plot(1:n_iter, accuracy, type = "l", xlab = "K", ylab = "Accuracy", main = "Accuracy of KNN Classifier", col = "blue")
points(1:50, accuracy, pch = 20, col = "red")
axis(1, at = seq(0, 50, by = 2), labels = seq(0, 50, by = 2))
axis(2, at = seq(0, 50, by = 2), labels = seq(0, 50, by = 2))
axis(1, at = seq(0, 50, by = 2), labels = seq(0, 50, by = 2))
axis(2, at = seq(0, 50, by = 2), labels = seq(0, 50, by = 2))
axis(0, at = seq(0, 50, by = 2), labels = seq(0, 50, by = 2))
Train_Scale_Label_HD <- scale(Train_Label_HD)
Test_Scale_HD <- scale(Test_HD)
Train_Scale_HD <- scale(Train_HD)
Train_Scale_Label_HD <- scale(Train_Label_HD)
Test_Scale_HD <- scale(Test_HD)
Test_Scale_Label_HD <- scale(Test_Label_HD)
HD_Dataset <- read.csv("C:\\Users\\Nico\\Desktop\\Progetto Morasca\\Classification\\heart.csv")
# Then we normalized the dataset so that the output remains unbiased.
normalize <- function(x){return ((x-min(x))/(max(x)-min(x)))}
HD_Dataset_Normalized <- as.data.frame(lapply(HD_Dataset, normalize))
n_iter <- 50
# We split the dataset into training set and testing set.
set.seed(123)
index <- sample(1:nrow(HD_Dataset_Normalized), 0.7 * nrow(HD_Dataset_Normalized))
Train_HD <- HD_Dataset_Normalized[index, 1:13]
Train_Label_HD <- HD_Dataset_Normalized[index, 14]
Test_HD <- HD_Dataset_Normalized[-index, 1:13]
Test_Label_HD <- HD_Dataset_Normalized[-index, 14]
accuracy <- c()
for (i in 1:n_iter) {
model <- knn(Train_HD, Test_HD, Train_Label_HD, k = i)
pred <- model
accuracy[i] <- mean(pred == Test_Label_HD)
cm <- confusionMatrix(model, Test_Label_HD)
}
model <- knn(Train_HD, Test_HD, Train_Label_HD, k = i)
pred <- model
accuracy[i] <- mean(pred == Test_Label_HD)
cm <- confusionMatrix(model, Test_Label_HD)
model <- knn(Train_HD, Test_HD, Train_Label_HD, k = i)
cm <- confusionMatrix(model, Test_Label_HD)
accuracy[i] <- mean(pred == Test_Label_HD)
confusionMatrix(model, testLabel)
confusionMatrix(model, Test_Label_HD)
accuracy[i] <- mean(model == Test_Label_HD)
plot(1:n_iter, accuracy, type = "l", xlab = "K", ylab = "Accuracy", main = "Accuracy of KNN Classifier", col = "blue")
points(1:50, accuracy, pch = 20, col = "red")
axis(1, at = seq(0, 50, by = 2), labels = seq(0, 50, by = 2))
axis(2, at = seq(0, 50, by = 2), labels = seq(0, 50, by = 2))
HD_Dataset <- read.csv("C:\\Users\\Nico\\Desktop\\Progetto Morasca\\Classification\\heart.csv")
# Then we normalized the dataset so that the output remains unbiased.
normalize <- function(x){return ((x-min(x))/(max(x)-min(x)))}
HD_Dataset_Normalized <- as.data.frame(lapply(HD_Dataset, normalize))
n_iter <- 50
# We split the dataset into training set and testing set.
set.seed(123)
index <- createDataPartition(HD_Dataset_Normalized$output, p = 0.7, list = FALSE)
Train_HD <- HD_Dataset_Normalized[index, 1:13]
Train_Label_HD <- HD_Dataset_Normalized[index, 14]
Test_HD <- HD_Dataset_Normalized[-index, 1:13]
Test_Label_HD <- HD_Dataset_Normalized[-index, 14]
model <- knn(Train_HD, Test_HD, Train_Label_HD, k = i)
for (i in 1:n_iter) {
model <- knn(Train_HD, Test_HD, Train_Label_HD, k = i)
cm <- confusionMatrix(model, Test_Label_HD)
accuracy[i] <- cm
}
Train_Label_HD <- as.factor(Train_Label_HD)
Test_Label_HD <- as.factor(Test_Label_HD)
Train_Label_HD <- factor(Train_Label_HD, levels = unique(c(Train_Label_HD, Test_Label_HD)))
Test_Label_HD <- factor(Test_Label_HD, levels = unique(c(Train_Label_HD, Test_Label_HD)))
accuracy <- c()
for (i in 1:n_iter) {
model <- knn(Train_HD, Test_HD, Train_Label_HD, k = i)
cm <- confusionMatrix(model, Test_Label_HD)
accuracy[i] <- cm$
}
for (i in 1:n_iter) {
model <- knn(Train_HD, Test_HD, Train_Label_HD, k = i)
cm <- confusionMatrix(model, Test_Label_HD)
accuracy[i] <- cm$overall[1]
}
plot(1:n_iter, accuracy, type = "l", xlab = "K", ylab = "Accuracy", main = "Accuracy of KNN Classifier", col = "blue")
points(1:50, accuracy, pch = 20, col = "red")
axis(1, at = seq(0, 50, by = 2), labels = seq(0, 50, by = 2))
axis(2, at = seq(0, 50, by = 2), labels = seq(0, 50, by = 2))
jaccard <- (cm$table[1, 1] + cm$table[2, 2] + cm$table[3, 3]) / sum(cm$table)
cm$table
jaccard <- (cm$table[1, 1] + cm$table[2, 2]) / sum(cm$table)
jaccard <- (cm$table[1, 1] + cm$table[2, 2]) / sum(cm$table)
markedness <- (cm$table[1, 1] + cm$table[2, 2]) / (cm$table[1, 1] + cm$table[2, 2] + cm$table[1, 2] + cm$table[2, 1])
library(DescTools)
install.packages("DescTools")
library(DescTools)
jaccard[i] <- Jaccard(model, Test_Label_HD)
library(caTools)
library(class)
library(e1071)
library(caret)
library(Amelia)
library(DescTools)
HD_Dataset <- read.csv("C:\\Users\\Nico\\Desktop\\Progetto Morasca\\Classification\\heart.csv")
# Then we normalized the dataset so that the output remains unbiased.
normalize <- function(x){return ((x-min(x))/(max(x)-min(x)))}
HD_Dataset_Normalized <- as.data.frame(lapply(HD_Dataset, normalize))
n_iter <- 50
# We split the dataset into training set and testing set.
set.seed(123)
index <- createDataPartition(HD_Dataset_Normalized$output, p = 0.7, list = FALSE)
Train_HD <- HD_Dataset_Normalized[index, 1:13]
Train_Label_HD <- HD_Dataset_Normalized[index, 14]
Test_HD <- HD_Dataset_Normalized[-index, 1:13]
Test_Label_HD <- HD_Dataset_Normalized[-index, 14]
Train_Label_HD <- as.factor(Train_Label_HD)
Test_Label_HD <- as.factor(Test_Label_HD)
Train_Label_HD <- factor(Train_Label_HD, levels = unique(c(Train_Label_HD, Test_Label_HD)))
Test_Label_HD <- factor(Test_Label_HD, levels = unique(c(Train_Label_HD, Test_Label_HD)))
accuracy <- c()
jaccard <- c()
markedness <- c()
for (i in 1:n_iter) {
model <- knn(Train_HD, Test_HD, Train_Label_HD, k = i)
cm <- confusionMatrix(model, Test_Label_HD)
accuracy[i] <- cm$overall[1]
jaccard[i] <- Jaccard(model, Test_Label_HD)
}
cm$table
jaccard <- (cm$table[1, 1] / (cm$table[1, 1] + cm$table[1, 2] + cm$table[2, 1]))
jaccard
markedness <- ((cm$table[1, 1]/(cm$table[1, 1] + cm$table[1, 2]))+((cm$table[2, 1])/(cm$table[2, 1] + cm$table[2, 2])))
markedness
jaccard <- (cm$table[1, 1] / (cm$table[1, 1] + cm$table[1, 2] + cm$table[2, 1]))
jouden <- ((cm$table[1, 1]/(cm$table[1, 1]+cm$table[2, 1])) - ((cm$table[1, 2])/(cm$table[1, 2]+cm$table[2, 2])))
markedness <- ((cm$table[1, 1]/(cm$table[1, 1] + cm$table[1, 2]))-((cm$table[2, 1])/(cm$table[2, 1] + cm$table[2, 2])))
jaccard
jouden
markedness
plot(1:n_iter, accuracy, type = "l", xlab = "K", ylab = "Accuracy", ylim = c(0.5, 1), main = "Accuracy of KNN Classifier", col = "blue")
plot(1:n_iter, accuracy, type = "l", xlab = "K", ylab = "Accuracy", ylim = c(0.5, 1), main = "Accuracy of KNN Classifier", col = "blue")
for (i in 1:n_iter) {
model <- knn(Train_HD, Test_HD, Train_Label_HD, k = i)
cm <- confusionMatrix(model, Test_Label_HD)
accuracy[i] <- cm$overall[1]
}
plot(1:n_iter, accuracy, type = "l", xlab = "K", ylab = "Accuracy", ylim = c(0.5, 1), main = "Accuracy of KNN Classifier", col = "blue")
points(1:50, accuracy, pch = 20, col = "red")
axis(1, at = seq(0, 50, by = 2), labels = seq(0, 50, by = 2))
plot(1:n_iter, accuracy, type = "l", xlab = "K", ylab = "Accuracy", ylim = c(0.75, 1), main = "Accuracy of KNN Classifier", col = "blue")
points(1:50, accuracy, pch = 20, col = "red")
cm$table
axis(1, at = seq(0, 50, by = 2), labels = seq(0, 50, by = 2))
plot(1:n_iter, accuracy, type = "l", xlab = "K", ylab = "Accuracy", main = "Accuracy of KNN Classifier", col = "blue")
points(1:50, accuracy, pch = 20, col = "red")
axis(1, at = seq(0, 50, by = 2), labels = seq(0, 50, by = 2))
heatmap(cm, Colv = FALSE, Rowv = FALSE)
plot(cm)
HD_Dataset <- read.csv("C:\\Users\\Nico\\Desktop\\Progetto Morasca\\Classification\\heart.csv")
# Then we normalized the dataset so that the output remains unbiased.
normalize <- function(x){return ((x-min(x))/(max(x)-min(x)))}
HD_Dataset_Normalized <- as.data.frame(lapply(HD_Dataset, normalize))
n_iter <- 50
# We split the dataset into training set and testing set.
set.seed(123)
index <- createDataPartition(HD_Dataset_Normalized$output, p = 0.7, list = FALSE)
Train_HD <- HD_Dataset_Normalized[index, 1:13]
Train_Label_HD <- HD_Dataset_Normalized[index, 14]
Test_HD <- HD_Dataset_Normalized[-index, 1:13]
Test_Label_HD <- HD_Dataset_Normalized[-index, 14]
Train_Label_HD <- as.factor(Train_Label_HD)
Test_Label_HD <- as.factor(Test_Label_HD)
Train_Label_HD <- factor(Train_Label_HD, levels = unique(c(Train_Label_HD, Test_Label_HD)))
Test_Label_HD <- factor(Test_Label_HD, levels = unique(c(Train_Label_HD, Test_Label_HD)))
accuracy <- c()
for (i in 1:n_iter) {
model <- knn(Train_HD, Test_HD, Train_Label_HD, k = i)
cm <- confusionMatrix(model, Test_Label_HD)
accuracy[i] <- cm$overall[1]
}
plot(1:n_iter, accuracy, type = "l", xlab = "K", ylab = "Accuracy", main = "Accuracy of KNN Classifier", col = "blue")
points(1:50, accuracy, pch = 20, col = "red")
axis(1, at = seq(0, 50, by = 2), labels = seq(0, 50, by = 2))
plot(cm)
plot(cm)
print(cm)
tn <- cm$table[2, 2]
fp <- cm$table[1, 2]
fn <- cm$table[2, 1]
tp <- cm$table[1, 1]
barplot(c(tn, fp, fn, tp), beside = TRUE,
col = c("red", "blue"),
legend = rownames(cm$table))
plot(c(tn, fp, fn, tp))
heatmap(c(tn, fp, fn, tp), Colv = FALSE, Rowv = FALS)
heatmap(matrix(c(tn, fp, fn, tp), nrow = 2, ncol = 2), Colv = FALSE, Rowv = FALS)
heatmap(matrix(c(tn, fp, fn, tp), nrow = 2, ncol = 2), Colv = FALSE, Rowv = FALSE)
df <- as.data.frame(cm)
df <- as.data.frame(matrix(c(tp, fp, dn, tx), nrow = 2, ncol = 2))
df <- as.data.frame(matrix(c(tp, fp, fn, tn), nrow = 2, ncol = 2))
# add row and column labels to the data frame
colnames(df) <- c("Predicted No", "Predicted Yes")
rownames(df) <- c("Actual No", "Actual Yes")
# draw the confusion matrix
ggplot(df, aes(x = rownames(df), y = colnames(df))) +
geom_tile(aes(fill = df), color = "white") +
scale_fill_gradient(low = "white", high = "steelblue") +
geom_text(aes(label = df), color = "white") +
theme_void() +
theme(axis.line = element_blank(),
axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
axis.text.y = element_text(hjust = 1, vjust = 0.5))
# draw the confusion matrix
ggplot(df, aes(x = rownames(df), y = colnames(df))) +
geom_tile(aes(fill = df), color = "white") +
scale_fill_gradient(low = "white", high = "steelblue") +
geom_text(aes(label = df), color = "white") +
theme_void() +
theme(axis.line = element_blank(),
axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
axis.text.y = element_text(hjust = 1, vjust = 0.5))
df$df <- as.factor(df%df)
df <- as.data.frame(matrix(c(tp, fp, fn, tn), nrow = 2, ncol = 2))
# add row and column labels to the data frame
colnames(df) <- c("Predicted No", "Predicted Yes")
rownames(df) <- c("Actual No", "Actual Yes")
df$df <- as.factor(df%df)
df$df <- as.factor(df$df)
df$df <- as.factor(df$df)
df <- as.data.frame(matrix(c(tp, fp, fn, tn), nrow = 2, ncol = 2))
# add row and column labels to the data frame
colnames(df) <- c("Predicted No", "Predicted Yes")
rownames(df) <- c("Actual No", "Actual Yes")
df$df <- as.factor(df$df)
df$df <- as.factor(df$df)
accuracy:NB <- c()
HD_Dataset <- read.csv("C:\\Users\\Nico\\Desktop\\Progetto Morasca\\Classification\\heart.csv")
# Then we normalized the dataset so that the output remains unbiased.
normalize <- function(x){return ((x-min(x))/(max(x)-min(x)))}
HD_Dataset_Normalized <- as.data.frame(lapply(HD_Dataset, normalize))
n_iter <- 50
# We split the dataset into training set and testing set.
set.seed(123)
index <- createDataPartition(HD_Dataset_Normalized$output, p = 0.7, list = FALSE)
Train_HD <- HD_Dataset_Normalized[index, 1:13]
Train_Label_HD <- HD_Dataset_Normalized[index, 14]
Test_HD <- HD_Dataset_Normalized[-index, 1:13]
Test_Label_HD <- HD_Dataset_Normalized[-index, 14]
Train_Label_HD <- as.factor(Train_Label_HD)
Test_Label_HD <- as.factor(Test_Label_HD)
Train_Label_HD <- factor(Train_Label_HD, levels = unique(c(Train_Label_HD, Test_Label_HD)))
Test_Label_HD <- factor(Test_Label_HD, levels = unique(c(Train_Label_HD, Test_Label_HD)))
accuracy_NB <- c()
for (i in 1:n_iter) {
model_NB <- naiveBayes(Train_HD, Train_Label_HD)
cm_NB <- confusionMatrix(model_NB, Test_Label_HD)
accuracy_NB[i] <- cm$overall[1]
}
accuracy_NB <- c()
for (i in 1:n_iter) {
model_NB <- naiveBayes(Train_HD, data = Train_Label_HD)
pred <-predict(model_NB, newdata = Test_HD)
accuracy_NB[i] <- mean(pred == Test_Label_HD)
}
model_NB <- naiveBayes(Train_HD, data = Train_Label_HD)
HD_Dataset <- read.csv("C:\\Users\\Nico\\Desktop\\Progetto Morasca\\Classification\\heart.csv")
# Then we normalized the dataset so that the output remains unbiased.
normalize <- function(x){return ((x-min(x))/(max(x)-min(x)))}
HD_Dataset_Normalized <- as.data.frame(lapply(HD_Dataset, normalize))
n_iter <- 50
# We split the dataset into training set and testing set.
set.seed(123)
index <- createDataPartition(HD_Dataset_Normalized$output, p = 0.7, list = FALSE)
Train_HD <- HD_Dataset_Normalized[index, 1:13]
Train_Label_HD <- HD_Dataset_Normalized[index, 14]
Test_HD <- HD_Dataset_Normalized[-index, 1:13]
Test_Label_HD <- HD_Dataset_Normalized[-index, 14]
Train_Label_HD <- as.factor(Train_Label_HD)
Test_Label_HD <- as.factor(Test_Label_HD)
Train_Label_HD <- factor(Train_Label_HD, levels = unique(c(Train_Label_HD, Test_Label_HD)))
Test_Label_HD <- factor(Test_Label_HD, levels = unique(c(Train_Label_HD, Test_Label_HD)))
accuracy_NB <- c()
for (i in 1:n_iter) {
model_NB <- naiveBayes(Train_HD, data = Train_Label_HD)
pred <-predict(model_NB, newdata = Test_HD)
accuracy_NB[i] <- mean(pred == Test_Label_HD)
}
model_NB <- naiveBayes(Train_HD, Train_Label_HD)
pred <-predict(model_NB, newdata = Test_HD)
pred <-predict(model_NB, Test_HD)
accuracy_NB[i] <- mean(pred == Test_Label_HD)
for (i in 1:n_iter) {
model_NB <- naiveBayes(Train_HD, Train_Label_HD)
pred <- predict(model_NB, Test_HD)
cm_NB <- confusionMatrix(pred, Test_Label_HD)
accuracy_NB[i] <- cm_NB$overall[1]
}
accuracy_knn <- c()
for (i in 1:n_iter) {
model <- knn(Train_HD, Test_HD, Train_Label_HD, k = i)
pred <- predict(model, Test_HD)
cm <- confusionMatrix(pred, Test_Label_HD)
accuracy_knn[i] <- cm$overall[1]
}
HD_Dataset <- read.csv("C:\\Users\\Nico\\Desktop\\Progetto Morasca\\Classification\\heart.csv")
# Then we normalized the dataset so that the output remains unbiased.
normalize <- function(x){return ((x-min(x))/(max(x)-min(x)))}
HD_Dataset_Normalized <- as.data.frame(lapply(HD_Dataset, normalize))
n_iter <- 50
# We split the dataset into training set and testing set.
set.seed(123)
index <- createDataPartition(HD_Dataset_Normalized$output, p = 0.7, list = FALSE)
Train_HD <- HD_Dataset_Normalized[index, 1:13]
Train_Label_HD <- HD_Dataset_Normalized[index, 14]
Test_HD <- HD_Dataset_Normalized[-index, 1:13]
Test_Label_HD <- HD_Dataset_Normalized[-index, 14]
Train_Label_HD <- as.factor(Train_Label_HD)
Test_Label_HD <- as.factor(Test_Label_HD)
Train_Label_HD <- factor(Train_Label_HD, levels = unique(c(Train_Label_HD, Test_Label_HD)))
Test_Label_HD <- factor(Test_Label_HD, levels = unique(c(Train_Label_HD, Test_Label_HD)))
accuracy_knn <- c()
for (i in 1:n_iter) {
model <- knn(Train_HD, Test_HD, Train_Label_HD, k = i)
pred <- predict(model, Test_HD)
cm <- confusionMatrix(pred, Test_Label_HD)
accuracy_knn[i] <- cm$overall[1]
}
HD_Dataset <- read.csv("C:\\Users\\Nico\\Desktop\\Progetto Morasca\\Classification\\heart.csv")
# Then we normalized the dataset so that the output remains unbiased.
normalize <- function(x){return ((x-min(x))/(max(x)-min(x)))}
HD_Dataset_Normalized <- as.data.frame(lapply(HD_Dataset, normalize))
n_iter <- 50
# We split the dataset into training set and testing set.
set.seed(123)
index <- createDataPartition(HD_Dataset_Normalized$output, p = 0.7, list = FALSE)
Train_HD <- HD_Dataset_Normalized[index, 1:13]
Train_Label_HD <- HD_Dataset_Normalized[index, 14]
Test_HD <- HD_Dataset_Normalized[-index, 1:13]
Test_Label_HD <- HD_Dataset_Normalized[-index, 14]
Train_Label_HD <- as.factor(Train_Label_HD)
Test_Label_HD <- as.factor(Test_Label_HD)
Train_Label_HD <- factor(Train_Label_HD, levels = unique(c(Train_Label_HD, Test_Label_HD)))
Test_Label_HD <- factor(Test_Label_HD, levels = unique(c(Train_Label_HD, Test_Label_HD)))
accuracy_knn <- c()
for (i in 1:n_iter) {
model <- knn(Train_HD, Test_HD, Train_Label_HD, k = i)
cm <- confusionMatrix(model, Test_Label_HD)
accuracy_knn[i] <- cm$overall[1]
}
plot(1:n_iter, accuracy_knn, type = "l", xlab = "K", ylab = "Accuracy", main = "Accuracy of KNN Classifier", col = "blue")
points(1:50, accuracy_knn, pch = 20, col = "red")
axis(1, at = seq(0, 50, by = 2), labels = seq(0, 50, by = 2))
jaccard <- (cm$table[1, 1] / (cm$table[1, 1] + cm$table[1, 2] + cm$table[2, 1]))
jouden <- ((cm$table[1, 1]/(cm$table[1, 1]+cm$table[2, 1])) - ((cm$table[1, 2])/(cm$table[1, 2]+cm$table[2, 2])))
markedness <- ((cm$table[1, 1]/(cm$table[1, 1] + cm$table[1, 2]))-((cm$table[2, 1])/(cm$table[2, 1] + cm$table[2, 2])))
accuracy_NB <- c()
for (i in 1:n_iter) {
model_NB <- naiveBayes(Train_HD, Train_Label_HD)
pred_NB <- predict(model_NB, Test_HD)
cm_NB <- confusionMatrix(pred_NB, Test_Label_HD)
accuracy_NB[i] <- cm_NB$overall[1]
}
plot(1:n_iter, accuracy_NB, type = "l", xlab = "K", ylab = "Accuracy", main = "Accuracy of KNN Classifier", col = "blue")
for (i in 1:n_iter) {
model_NB <- naiveBayes(Train_HD, Train_Label_HD)
pred_NB <- predict(model_NB, Test_HD)
cm_NB <- confusionMatrix(pred_NB, Test_Label_HD)
print(cm_NB$table)
accuracy_NB[i] <- cm_NB$overall[1]
}
NB_Class <- naiveBayes(Train_HD, Train_Label_HD)
pred <-predict(model_NB, Test_HD)
model_NB <- naiveBayes(Train_HD, Train_Label_HD)
pred <-predict(model_NB, Test_HD)
cm_NB <- confusionMatrix(pred, Test_Label_HD)
print(cm_NB$table)
print("Overall:", cm_NB$overall[1])
cm_NB <- confusionMatrix(pred, Test_Label_HD)
print("Overall:", cm_NB$overall[1])
cm_NB$overall[1]
print(cm_NB$overall[1])
print(cm_NB$overall[1])
jaccard_knn <- (cm$table[1, 1] / (cm$table[1, 1] + cm$table[1, 2] + cm$table[2, 1]))
jouden_knn <- ((cm$table[1, 1]/(cm$table[1, 1]+cm$table[2, 1])) - ((cm$table[1, 2])/(cm$table[1, 2]+cm$table[2, 2])))
markedness_knn <- ((cm$table[1, 1]/(cm$table[1, 1] + cm$table[1, 2]))-((cm$table[2, 1])/(cm$table[2, 1] + cm$table[2, 2])))
model_NB <- naiveBayes(Train_HD, Train_Label_HD)
pred <-predict(model_NB, Test_HD)
cm_NB <- confusionMatrix(pred, Test_Label_HD)
print(cm_NB$overall[1])
jaccard_NB <- (cm$table[1, 1] / (cm$table[1, 1] + cm$table[1, 2] + cm$table[2, 1]))
jouden_NB <- ((cm$table[1, 1]/(cm$table[1, 1]+cm$table[2, 1])) - ((cm$table[1, 2])/(cm$table[1, 2]+cm$table[2, 2])))
markedness_NB <- ((cm$table[1, 1]/(cm$table[1, 1] + cm$table[1, 2]))-((cm$table[2, 1])/(cm$table[2, 1] + cm$table[2, 2])))
print("JACCARD")
print(paste("KNN JACCARD: ", jaccard_knn))
print(paste("NAIVE BAYES JACCARD: ", jaccard_NB))
print(paste("KNN JOUDEN: ", jouden_knn))
print(paste("NAIVE BAYES JOUDEN: ", jouden_NB))
print(paste("KNN MARKEDNESS: ", markedness_knn))
print(paste("NAIVE BAYES MARKEDNESS: ", markedness_NB))
model_NB <- naiveBayes(Train_HD, Train_Label_HD)
pred <-predict(model_NB, Test_HD)
cm_NB <- confusionMatrix(pred, Test_Label_HD)
print(cm_NB$overall[1])
jaccard_NB <- (cm_NB$table[1, 1] / (cm_NB$table[1, 1] + cm_NB$table[1, 2] + cm_NB$table[2, 1]))
jouden_NB <- ((cm_NB$table[1, 1]/(cm_NB$table[1, 1]+cm_NB$table[2, 1])) - ((cm_NB$table[1, 2])/(cm_NB$table[1, 2]+cm_NB$table[2, 2])))
markedness_NB <- ((cm_NB$table[1, 1]/(cm_NB$table[1, 1] + cm_NB$table[1, 2]))-((cm_NB$table[2, 1])/(cm_NB$table[2, 1] + cm_NB$table[2, 2])))
print("JACCARD")
print(paste("KNN JACCARD: ", jaccard_knn))
print(paste("NAIVE BAYES JACCARD: ", jaccard_NB))
print(paste("KNN JOUDEN: ", jouden_knn))
print(paste("NAIVE BAYES JOUDEN: ", jouden_NB))
print(paste("KNN MARKEDNESS: ", markedness_knn))
print(paste("NAIVE BAYES MARKEDNESS: ", markedness_NB))
HD_Dataset <- read.csv("C:\\Users\\Nico\\Desktop\\Progetto Morasca\\Classification\\heart.csv")
source("C:/Users/Nico/Desktop/Progetto Morasca/Classification/Classification.R")
install.packages("caTools")
install.packages("Amelia")
install.packages("class")
install.packages("caret")
source("C:/Users/Nico/Desktop/Progetto Morasca/Classification/Classification.R")
model <- knn(Train_HD, Test_HD, Train_Label_HD, k = i)
pred <-predict(model, Test_HD)
print("\n")
print(\n)
print(\\n)
print(/n)
print()
source("C:/Users/Nico/Desktop/Progetto Morasca/Classification/Classification.R")
cm$table
source("C:/Users/Nico/Desktop/Progetto Morasca/Classification/Classification.R")
print(cm_NB$table)
source("C:/Users/Nico/Desktop/Progetto Morasca/Classification/Classification.R")
source("C:/Users/Nico/Desktop/Progetto Morasca/Classification/Classification.R")
